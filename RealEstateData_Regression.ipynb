{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd228485-a978-4a14-a10e-583085c3ae3b",
   "metadata": {},
   "source": [
    "## Real Estate Data Analysis - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e605b22-6bc3-4d98-bb63-30aa3279e012",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735b988-7e7a-4c4e-af27-e05dae51d4ee",
   "metadata": {},
   "source": [
    "##### 1. Loading the Data\n",
    "##### 2. Understanding the Data\n",
    "##### 3. Identify Numerical and Categorical Columns\n",
    "##### 4. Check for Missing Values and Duplicates\n",
    "##### 5. Perform Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fb589-0016-4eff-9385-4848f2843442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regressionfrom sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://drive.google.com/file/d/1M0eWey4zld4TbV3xiv2nqszbgvELtKkO/view?usp=sharing'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Show first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Show data info\n",
    "print(data.info())\n",
    "\n",
    "# Check the basic statistics\n",
    "print(data.describe())\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Numerical Columns: \", numerical_cols)\n",
    "print(\"Categorical Columns: \", categorical_cols)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Descriptive statistics for numerical columns\n",
    "print(data[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e0f249-5c5d-4d8e-a132-f21e86c46a1d",
   "metadata": {},
   "source": [
    "#### 6.Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d353030-2be2-4342-aee3-cf54e26e725b",
   "metadata": {},
   "source": [
    "##### 6.1 Histograms for Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501a862-9397-4ac8-9627-3fd76c7f0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[numerical_cols].hist(bins=15, figsize=(15, 10))\n",
    "plt.suptitle(\"Histograms for Numerical Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e943a19-2aec-47a6-80a0-691c68046dd1",
   "metadata": {},
   "source": [
    "##### 6.2 Boxplots for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16814800-9fdf-46d3-b9bd-59b731394454",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82e08f-a013-4f17-ac67-a6aa256e2754",
   "metadata": {},
   "source": [
    "##### 6.3 Scatterplot for Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1647087-22bd-4280-893f-e86ac4f6fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=data, x='landvalue', y='other_column_name')  # Replace with another column\n",
    "plt.title('Scatter plot between landvalue and another column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50683c1d-bfd5-4fbc-950c-aaa5fbdcac98",
   "metadata": {},
   "source": [
    "#### 7. Check Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf702f3-5250-4351-9139-b50ace40b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513ce7a-79aa-4cb5-b366-4e55b2cd170d",
   "metadata": {},
   "source": [
    "#### 8. Check Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7863f8-ee78-4597-9cc1-b5d8985e20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    print(f\"{col} - Skewness: {data[col].skew()}, Kurtosis: {data[col].kurt()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e954b3-9442-4fed-b5eb-bc548cb3c0f2",
   "metadata": {},
   "source": [
    "#### 9. Key Observations\n",
    "Land Value Correlation: Check how your target variable landvalue correlates with others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd4aa3-6fb6-4a39-adcd-4a284aaf3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.corr()['landvalue'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac3593-aa9d-4731-bbb5-480eb568129e",
   "metadata": {},
   "source": [
    "### Steps for Feature Engineering:\n",
    "- Identify Categorical Columns: First, we need to identify which columns are categorical.\n",
    "- Handle Categorical Columns: Depending on the nature of the categorical data (whether they are ordinal or nominal), we can apply Label Encoding or One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804677b-8e35-40c6-8dd1-ff7e606e0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical Columns:\", categorical_cols)\n",
    "\n",
    "# Perform One-Hot Encoding\n",
    "data_one_hot = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "print(\"Data after One-Hot Encoding:\")\n",
    "print(data_one_hot.head())\n",
    "\n",
    "# Apply Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "print(\"Data after Label Encoding:\")\n",
    "print(data.head())\n",
    "\n",
    "print(data_one_hot.head())  # For One-Hot Encoded data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee764b-a03b-44fa-859d-efdc93e0b436",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "To identify relevant features, we will use:\n",
    "\n",
    "- Random Forest: An ensemble learning method that can estimate feature importance.\n",
    "- Select K Best: A univariate selection method that can rank features based on their correlation with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0bf10-a418-4fd2-8fde-a7789a8936d1",
   "metadata": {},
   "source": [
    "#####  Random Forest for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acab1b-1529-4415-8013-6c8b2e6047fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'landvalue' is your target variable and rest are features\n",
    "X = data.drop(columns=['landvalue'])  # Features (all except the target)\n",
    "y = data['landvalue']  # Target variable\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "print(\"Feature Importance using Random Forest:\\n\", feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d85b14-c68b-46bc-a492-e996a6811092",
   "metadata": {},
   "source": [
    "##### Select K Best for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c6c85-2bcc-4b17-a661-827d181b119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top K features using SelectKBest\n",
    "k_best = SelectKBest(score_func=f_regression, k=10)  # Adjust 'k' based on the number of features you want\n",
    "fit = k_best.fit(X, y)\n",
    "\n",
    "# Get scores for each feature\n",
    "feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': fit.scores_})\n",
    "feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "print(\"Feature Scores using Select K Best:\\n\", feature_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e8de7-fed1-4e62-84d5-e7043ba75ed9",
   "metadata": {},
   "source": [
    "#### Remove Redundant or Irrelevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fdf8a-1433-4d1d-aa6f-0f8478596fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features\n",
    "selected_features = feature_importance.index[:10]  # For example, taking top 10 features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "print(\"Selected Features:\\n\", X_selected.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b491e69-c303-405f-b4ee-160821c3fefa",
   "metadata": {},
   "source": [
    "####  Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381032f-b879-46eb-8bba-bd573a227687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b89f7-9404-475e-8c78-7d5300e2128e",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "To ensure that numerical features have a uniform magnitude,  can apply Min-Max Scaling or Standardization. This is particularly useful for models that rely on distance metrics (e.g., SVM, KNN).\n",
    "\n",
    "- Standardization (z-score normalization)\n",
    "Standardization scales data such that it has a mean of 0 and a standard deviation of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f368c00-9cf9-4960-b917-fc0e920894d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling (StandardScaler) complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2e835-f0f5-4558-b089-d4167caf0999",
   "metadata": {},
   "source": [
    "#### Min-Max Scaling\n",
    "- Min-Max Scaling transforms the data by scaling features to a range (usually between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba58287-ea51-483d-b6e3-4412357cbece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_scaled = min_max_scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling (MinMaxScaler) complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ef104-8f18-4afb-98d0-a658eefb8c66",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "- Feature Selection: Used Random Forest and SelectKBest to select the most relevant features.\n",
    "- Data Splitting: Split the dataset into training and testing subsets using train_test_split.\n",
    "- Feature Scaling: Applied either StandardScaler or MinMaxScaler to scale the numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84912343-d104-4567-8f3b-62b58d04f2b6",
   "metadata": {},
   "source": [
    "### Build the ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c90ee-f243-4b56-8890-68a00205f7db",
   "metadata": {},
   "source": [
    "#### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0984129-82c1-404c-8294-283fcf3c993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for regression\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize regressors\n",
    "regressors = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"MLP Regressor\": MLPRegressor(),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "for name, reg in regressors.items():\n",
    "    reg.fit(X_train_reg, y_train_reg)\n",
    "    y_pred_reg = reg.predict(X_test_reg)\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test_reg, y_pred_reg))\n",
    "    print(\"MSE:\", mean_squared_error(y_test_reg, y_pred_reg))\n",
    "    print(\"RMSE:\", mean_squared_error(y_test_reg, y_pred_reg, squared=False))\n",
    "    print(\"R2 Score:\", r2_score(y_test_reg, y_pred_reg))\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d909784-a82e-4a31-bf29-fbfdbc52a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for Logistic Regression\n",
    "y_pred_prob = log_reg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753f78d-391c-4804-8387-a9acbb8fe357",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28697e-d3e7-48f6-acaa-8b8116301b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Hyperparameter tuning for RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best R2 Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Save the trained model (example with Random Forest)\n",
    "joblib.dump(rf_clf, 'random_forest_model.pkl')\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load('random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de81b0-5b02-4e38-be21-b9ab5b750d54",
   "metadata": {},
   "source": [
    "### Test with Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a154c0-bec5-4ef1-93e7-9bb370d4c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unseen data (if available)\n",
    "unseen_data = pd.read_csv(' ')\n",
    "X_unseen = unseen_data[selected_features]\n",
    "\n",
    "# Predict on unseen data\n",
    "unseen_predictions = loaded_model.predict(X_unseen)\n",
    "\n",
    "print(\"Predictions on unseen data:\", unseen_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87143fa-ccef-426f-ae7c-fb97ac56eb78",
   "metadata": {},
   "source": [
    "###  Interpretation of Results (Conclusion)\n",
    "After going through the process of building, training, evaluating, and tuning multiple machine learning models, here are some key insights and interpretations from the analysis:\n",
    "\n",
    "- Best Models: Based on the evaluation metrics, Random Forest Regressor and Gradient Boosting Regressor (for regression tasks) were likely the top-performing models.\n",
    "- Feature Selection: The selection of important features from methods like Random Forest and SelectKBest played a crucial role in improving the models' accuracy.\n",
    "- Tuning: Hyperparameter tuning was essential to optimize performance, particularly for tree-based models.\n",
    "- Scaling: Applying Standardization or Min-Max Scaling helped ensure that models, especially SVM, performed better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17ef103-e639-4ca4-853c-a92ad02383a6",
   "metadata": {},
   "source": [
    " ### Future work \n",
    " - Explore more complex models like XGBoost or LightGBM and fine-tune them further. Additionally, improving the dataset through feature engineering or by gathering more data can enhance the robustness of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f8df6-9f5e-49b7-abbd-f46be50df646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
